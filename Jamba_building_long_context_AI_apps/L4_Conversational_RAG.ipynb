{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30694aa9-029f-4010-bed4-0a5c30b66106",
   "metadata": {},
   "source": [
    "# L7: Conversational RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ac10f-477d-40d3-97a3-e8cea3078814",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34ce155-7153-4cc6-82e2-9f4026201259",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd5fcd3-b07e-46cf-ab7f-4ce8cdbbf85b",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9977646b-f467-4e95-8fbe-31885271c273",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from ai21 import AI21Client\n",
    "from ai21.models.chat import ChatMessage\n",
    "import uuid\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c05a58-6346-4746-8a28-f6a74b7f9e7a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>utils.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8eeeaf-18a8-424d-a312-53a3381edfe0",
   "metadata": {},
   "source": [
    "## Load API key and create AI21Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca22225d-18ee-4114-926f-270c380221a3",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from utils import get_ai21_api_key\n",
    "ai21_api_key = get_ai21_api_key()\n",
    "client = AI21Client(api_key=ai21_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa53a6dd",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling POST http://jupyter-api-proxy.internal.dlai/rev-proxy/ai21 failed with a non-200 response code: 403 headers: Headers({'date': 'Fri, 11 Apr 2025 19:29:44 GMT', 'content-type': 'application/json', 'content-length': '60', 'connection': 'keep-alive', 'server': 'gunicorn', 'x-frame-options': 'DENY', 'vary': 'Accept-Language, origin', 'content-language': 'en', 'x-content-type-options': 'nosniff', 'referrer-policy': 'same-origin', 'cross-origin-opener-policy': 'same-origin'})\n"
     ]
    },
    {
     "ename": "AI21APIError",
     "evalue": "Failed with http status code: 403 (AI21APIError). Details: {\"error\": {\"message\": \"Accessing library/files is invalid\"}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAI21APIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m file_upload\n\u001b[0;32m----> 2\u001b[0m file_id \u001b[38;5;241m=\u001b[39m \u001b[43mfile_upload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/L7/utils.py:28\u001b[0m, in \u001b[0;36mfile_upload\u001b[0;34m(client)\u001b[0m\n\u001b[1;32m     25\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m new_file_name\n\u001b[1;32m     26\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10k_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;241m.\u001b[39mhex)\n\u001b[0;32m---> 28\u001b[0m file_id \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_id\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ai21/clients/studio/resources/studio_library.py:36\u001b[0m, in \u001b[0;36mLibraryFiles.create\u001b[0;34m(self, file_path, path, labels, public_url, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m files \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[1;32m     34\u001b[0m body \u001b[38;5;241m=\u001b[39m remove_not_given({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublicUrl\u001b[39m\u001b[38;5;124m\"\u001b[39m: public_url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs})\n\u001b[0;32m---> 36\u001b[0m raw_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_module_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m raw_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfileId\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ai21/clients/studio/resources/studio_resource.py:60\u001b[0m, in \u001b[0;36mStudioResource._post\u001b[0;34m(self, path, body, params, response_cls, stream_cls, stream, files)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post\u001b[39m(\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     52\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     files: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, BinaryIO]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     59\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m StreamT:\n\u001b[0;32m---> 60\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_http_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cast_response(\n\u001b[1;32m     70\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m     71\u001b[0m         response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m         streaming_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_get_streaming_decoder(),\n\u001b[1;32m     75\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ai21/http_client/http_client.py:110\u001b[0m, in \u001b[0;36mAI21HTTPClient.execute_http_request\u001b[0;34m(self, method, path, params, body, stream, files, extra_headers)\u001b[0m\n\u001b[1;32m    108\u001b[0m         handle_non_success_response(response\u001b[38;5;241m.\u001b[39mstatus_code, details)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m         \u001b[43mhandle_non_success_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ai21/http_client/base_http_client.py:49\u001b[0m, in \u001b[0;36mhandle_non_success_response\u001b[0;34m(status_code, response_text)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m503\u001b[39m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(details\u001b[38;5;241m=\u001b[39mresponse_text)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m AI21APIError(status_code, details\u001b[38;5;241m=\u001b[39mresponse_text)\n",
      "\u001b[0;31mAI21APIError\u001b[0m: Failed with http status code: 403 (AI21APIError). Details: {\"error\": {\"message\": \"Accessing library/files is invalid\"}}"
     ]
    }
   ],
   "source": [
    "from utils import file_upload\n",
    "file_id = file_upload(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcab8f77",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfile_id\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_id' is not defined"
     ]
    }
   ],
   "source": [
    "print(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865acf0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1613170d-fe40-416c-982c-2ba11bff8e97",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "from utils import call_convrag\n",
    "\n",
    "conversation_history = []\n",
    "def convrag_response(message):\n",
    "  conversation_history.append(ChatMessage(content=message, role=\"user\"))\n",
    "  chat_response = call_convrag(client, conversation_history)\n",
    "  # the LLM response to user query\n",
    "  response = chat_response.choices[0].content\n",
    "  # most relevant retrieved text segment\n",
    "  text_retrieval = chat_response.sources[0].text\n",
    "  # the file contains the retrieved text segment\n",
    "  file_retrieval = chat_response.sources[0].file_name\n",
    "  conversation_history.append(ChatMessage(content=response, role=\"assistant\"))\n",
    "  return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb78cce-079d-4f18-a2b7-03522e2d0637",
   "metadata": {},
   "source": [
    "## Prompt the Conversational RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b589ed4-1620-48b3-a3f3-bc13747a512c",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> üö®\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b8b996-f740-447e-b1f3-2578280f4854",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I cannot answer your questions based on the documents I have access to.\n"
     ]
    }
   ],
   "source": [
    "message = \"You are a financial analyst and what is the summary with Nvidia annual earnings report?\"\n",
    "\n",
    "response = convrag_response(message)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d84596ad-d502-4a55-846a-8b8ac120ee56",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling POST http://jupyter-api-proxy.internal.dlai/rev-proxy/ai21 failed with a non-200 response code: 500 headers: Headers({'date': 'Fri, 11 Apr 2025 19:38:36 GMT', 'content-type': 'application/json', 'content-length': '34', 'connection': 'keep-alive', 'server': 'gunicorn', 'request-id': '9de83c30-457d-9daf-a38d-cdafbf4d5f94', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'expect-ct': 'max-age=86400, enforce', 'referrer-policy': 'same-origin', 'x-content-type-options': 'nosniff', 'x-frame-options': 'SAMEORIGIN', 'x-xss-protection': '1; mode=block', 'cf-ray': '92ecf1f66e6a176a-SJC', 'vary': 'Accept-Language, origin', 'content-language': 'en', 'cross-origin-opener-policy': 'same-origin'})\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error occurred: Failed with http status code: 500 (AI21ServerError). Details: {\"detail\":\"Internal Server Error\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAI21ServerError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/work/L7/utils.py:40\u001b[0m, in \u001b[0;36mcall_convrag\u001b[0;34m(client, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconversational_rag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_extraction_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjamba-1.5-large\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquestion_answering_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjamba-1.5-large\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# labels=[\"10q\"],\u001b[39;49;00m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# max_segments = 15,\u001b[39;49;00m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# retrieval_similarity_threshold = 0.8, # Range: 0.5 ‚Äì 1.5\u001b[39;49;00m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# retrieval_strategy = 'segments',  # ['segments', 'add_neighbors', 'full_doc']\u001b[39;49;00m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# max_neighbors = 2, # Used only when retrieval_strategy = 'add_neighbors'\u001b[39;49;00m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# hybrid_search_alpha = 0.98 # Range: 0.0 ‚Äì 1.0. 1.0 means using only dense embeddings; 0.0 means using only keyword search.\u001b[39;49;00m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ai21/clients/studio/resources/studio_conversational_rag.py:43\u001b[0m, in \u001b[0;36mStudioConversationalRag.create\u001b[0;34m(self, messages, path, labels, file_ids, max_segments, retrieval_strategy, retrieval_similarity_threshold, max_neighbors, hybrid_search_alpha, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_body(\n\u001b[1;32m     31\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m     32\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     41\u001b[0m )\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_module_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConversationalRagResponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ai21/clients/studio/resources/studio_resource.py:60\u001b[0m, in \u001b[0;36mStudioResource._post\u001b[0;34m(self, path, body, params, response_cls, stream_cls, stream, files)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post\u001b[39m(\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     52\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     files: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, BinaryIO]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     59\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m StreamT:\n\u001b[0;32m---> 60\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_http_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cast_response(\n\u001b[1;32m     70\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m     71\u001b[0m         response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m         streaming_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_get_streaming_decoder(),\n\u001b[1;32m     75\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ai21/http_client/http_client.py:110\u001b[0m, in \u001b[0;36mAI21HTTPClient.execute_http_request\u001b[0;34m(self, method, path, params, body, stream, files, extra_headers)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m         \u001b[43mhandle_non_success_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ai21/http_client/base_http_client.py:46\u001b[0m, in \u001b[0;36mhandle_non_success_response\u001b[0;34m(status_code, response_text)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AI21ServerError(details\u001b[38;5;241m=\u001b[39mresponse_text)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m503\u001b[39m:\n",
      "\u001b[0;31mAI21ServerError\u001b[0m: Failed with http status code: 500 (AI21ServerError). Details: {\"detail\":\"Internal Server Error\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow much did the Nvidia\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms revenue increase in the period?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mconvrag_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m, in \u001b[0;36mconvrag_response\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvrag_response\u001b[39m(message):\n\u001b[1;32m      5\u001b[0m   conversation_history\u001b[38;5;241m.\u001b[39mappend(ChatMessage(content\u001b[38;5;241m=\u001b[39mmessage, role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m   chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mcall_convrag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation_history\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;66;03m# the LLM response to user query\u001b[39;00m\n\u001b[1;32m      8\u001b[0m   response \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/work/L7/utils.py:53\u001b[0m, in \u001b[0;36mcall_convrag\u001b[0;34m(client, message)\u001b[0m\n\u001b[1;32m     40\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mconversational_rag\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     41\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m     42\u001b[0m         query_extraction_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjamba-1.5-large\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;66;03m# hybrid_search_alpha = 0.98 # Range: 0.0 ‚Äì 1.0. 1.0 means using only dense embeddings; 0.0 means using only keyword search.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chat_response\u001b[38;5;241m.\u001b[39mcontext_retrieved \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_response\u001b[38;5;241m.\u001b[39manswer_in_context:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;66;03m# context_retrieved: [boolean] True if the RAG engine was able to find segments related to the user's query.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;66;03m# answer_in_context: [boolean] True if an answer was found in the provided documents.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     response \u001b[38;5;241m=\u001b[39m SimpleNamespace(choices\u001b[38;5;241m=\u001b[39m[SimpleNamespace(content\u001b[38;5;241m=\u001b[39mDEFAULT_RESPONSE)], sources\u001b[38;5;241m=\u001b[39m[SimpleNamespace(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n",
      "\u001b[0;31mException\u001b[0m: Error occurred: Failed with http status code: 500 (AI21ServerError). Details: {\"detail\":\"Internal Server Error\"}"
     ]
    }
   ],
   "source": [
    "message = \"How much did the Nvidia's revenue increase in the period?\"\n",
    "\n",
    "response = convrag_response(message)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c68d5b6-b7c4-4fa5-bb7b-2e4393e7d1e8",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling POST http://jupyter-api-proxy.internal.dlai/rev-proxy/ai21 failed with a non-200 response code: 500 headers: Headers({'date': 'Fri, 11 Apr 2025 19:25:13 GMT', 'content-type': 'application/json', 'content-length': '34', 'connection': 'keep-alive', 'server': 'gunicorn', 'request-id': 'fd24ad6e-f405-f3a9-e39f-c133d033bd48', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'expect-ct': 'max-age=86400, enforce', 'referrer-policy': 'same-origin', 'x-content-type-options': 'nosniff', 'x-frame-options': 'SAMEORIGIN', 'x-xss-protection': '1; mode=block', 'cf-ray': '92ecde588a9acf22-SJC', 'vary': 'Accept-Language, origin', 'content-language': 'en', 'cross-origin-opener-policy': 'same-origin'})\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error occurred: Failed with http status code: 500 (AI21ServerError). Details: {\"detail\":\"Internal Server Error\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAI21ServerError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/work/L7/utils.py:40\u001b[0m, in \u001b[0;36mcall_convrag\u001b[0;34m(client, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconversational_rag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_extraction_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjamba-1.5-large\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquestion_answering_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjamba-1.5-large\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# labels=[\"10q\"],\u001b[39;49;00m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# max_segments = 15,\u001b[39;49;00m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# retrieval_similarity_threshold = 0.8, # Range: 0.5 ‚Äì 1.5\u001b[39;49;00m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# retrieval_strategy = 'segments',  # ['segments', 'add_neighbors', 'full_doc']\u001b[39;49;00m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# max_neighbors = 2, # Used only when retrieval_strategy = 'add_neighbors'\u001b[39;49;00m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# hybrid_search_alpha = 0.98 # Range: 0.0 ‚Äì 1.0. 1.0 means using only dense embeddings; 0.0 means using only keyword search.\u001b[39;49;00m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ai21/clients/studio/resources/studio_conversational_rag.py:43\u001b[0m, in \u001b[0;36mStudioConversationalRag.create\u001b[0;34m(self, messages, path, labels, file_ids, max_segments, retrieval_strategy, retrieval_similarity_threshold, max_neighbors, hybrid_search_alpha, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_body(\n\u001b[1;32m     31\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m     32\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     41\u001b[0m )\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_module_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConversationalRagResponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ai21/clients/studio/resources/studio_resource.py:60\u001b[0m, in \u001b[0;36mStudioResource._post\u001b[0;34m(self, path, body, params, response_cls, stream_cls, stream, files)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post\u001b[39m(\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     52\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     files: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, BinaryIO]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     59\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m StreamT:\n\u001b[0;32m---> 60\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_http_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cast_response(\n\u001b[1;32m     70\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m     71\u001b[0m         response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m         streaming_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_get_streaming_decoder(),\n\u001b[1;32m     75\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ai21/http_client/http_client.py:110\u001b[0m, in \u001b[0;36mAI21HTTPClient.execute_http_request\u001b[0;34m(self, method, path, params, body, stream, files, extra_headers)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m         \u001b[43mhandle_non_success_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ai21/http_client/base_http_client.py:46\u001b[0m, in \u001b[0;36mhandle_non_success_response\u001b[0;34m(status_code, response_text)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AI21ServerError(details\u001b[38;5;241m=\u001b[39mresponse_text)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m503\u001b[39m:\n",
      "\u001b[0;31mAI21ServerError\u001b[0m: Failed with http status code: 500 (AI21ServerError). Details: {\"detail\":\"Internal Server Error\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould I buy Nvidia stock now?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mconvrag_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m, in \u001b[0;36mconvrag_response\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvrag_response\u001b[39m(message):\n\u001b[1;32m      5\u001b[0m   conversation_history\u001b[38;5;241m.\u001b[39mappend(ChatMessage(content\u001b[38;5;241m=\u001b[39mmessage, role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m   chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mcall_convrag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation_history\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;66;03m# the LLM response to user query\u001b[39;00m\n\u001b[1;32m      8\u001b[0m   response \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/work/L7/utils.py:53\u001b[0m, in \u001b[0;36mcall_convrag\u001b[0;34m(client, message)\u001b[0m\n\u001b[1;32m     40\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mconversational_rag\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     41\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m     42\u001b[0m         query_extraction_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjamba-1.5-large\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;66;03m# hybrid_search_alpha = 0.98 # Range: 0.0 ‚Äì 1.0. 1.0 means using only dense embeddings; 0.0 means using only keyword search.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chat_response\u001b[38;5;241m.\u001b[39mcontext_retrieved \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_response\u001b[38;5;241m.\u001b[39manswer_in_context:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;66;03m# context_retrieved: [boolean] True if the RAG engine was able to find segments related to the user's query.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;66;03m# answer_in_context: [boolean] True if an answer was found in the provided documents.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     response \u001b[38;5;241m=\u001b[39m SimpleNamespace(choices\u001b[38;5;241m=\u001b[39m[SimpleNamespace(content\u001b[38;5;241m=\u001b[39mDEFAULT_RESPONSE)], sources\u001b[38;5;241m=\u001b[39m[SimpleNamespace(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n",
      "\u001b[0;31mException\u001b[0m: Error occurred: Failed with http status code: 500 (AI21ServerError). Details: {\"detail\":\"Internal Server Error\"}"
     ]
    }
   ],
   "source": [
    "message = \"Should I buy Nvidia stock now?\"\n",
    "\n",
    "response = convrag_response(message)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54091d67",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09040e8d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6438d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c434557",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b32e5a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d23ff720-0206-450d-9f25-04ac93163f74",
   "metadata": {},
   "source": [
    "## Create a gradio chat app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8948e68-ca41-4497-9de0-e482c8c0b03f",
   "metadata": {
    "height": 353
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  https://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://s172-29-113-150p7860.lab-aws-production.deeplearning.ai/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling POST http://jupyter-api-proxy.internal.dlai/rev-proxy/ai21 failed with a non-200 response code: 500 headers: Headers({'date': 'Fri, 11 Apr 2025 19:33:30 GMT', 'content-type': 'application/json', 'content-length': '34', 'connection': 'keep-alive', 'server': 'gunicorn', 'request-id': '86a79e48-f332-372d-3d84-b9d81efd85f9', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'expect-ct': 'max-age=86400, enforce', 'referrer-policy': 'same-origin', 'x-content-type-options': 'nosniff', 'x-frame-options': 'SAMEORIGIN', 'x-xss-protection': '1; mode=block', 'cf-ray': '92ecea7aabcf67a7-SJC', 'vary': 'Accept-Language, origin', 'content-language': 'en', 'cross-origin-opener-policy': 'same-origin'})\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/work/L7/utils.py\", line 40, in call_convrag\n",
      "    chat_response = client.beta.conversational_rag.create(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ai21/clients/studio/resources/studio_conversational_rag.py\", line 43, in create\n",
      "    return self._post(path=f\"/{self._module_name}\", body=body, response_cls=ConversationalRagResponse)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ai21/clients/studio/resources/studio_resource.py\", line 60, in _post\n",
      "    response = self._client.execute_http_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ai21/http_client/http_client.py\", line 110, in execute_http_request\n",
      "    handle_non_success_response(response.status_code, response.text)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/ai21/http_client/base_http_client.py\", line 46, in handle_non_success_response\n",
      "    raise AI21ServerError(details=response_text)\n",
      "ai21.errors.AI21ServerError: Failed with http status code: 500 (AI21ServerError). Details: {\"detail\":\"Internal Server Error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/gradio/queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/gradio/blocks.py\", line 2043, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/gradio/blocks.py\", line 1590, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2505, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 1005, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/gradio/utils.py\", line 865, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_19/2315724596.py\", line 6, in convrag_response\n",
      "    chat_response = call_convrag(client, conversation_history)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/work/L7/utils.py\", line 53, in call_convrag\n",
      "    raise Exception(f\"Error occurred: {e}\")\n",
      "Exception: Error occurred: Failed with http status code: 500 (AI21ServerError). Details: {\"detail\":\"Internal Server Error\"}\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=convrag_response,\n",
    "    inputs=[gr.Textbox(label=\"Your questions:\", lines=2)],\n",
    "    outputs=[gr.Textbox(label=\"AI21 Conversational RAG answer:\", lines=2)],\n",
    "    examples=[\n",
    "    \"How have revenue, gross margin, and net income trended over the past year?\",\n",
    "    \"What are the actions taken by the company about sustainability?\",\n",
    "    \"What are the main risks of the company?\",\n",
    "    \"How is the company allocating its capital (e.g., dividends, share repurchases, acquisitions)?\",\n",
    "    \"Are there any concerning trends in operating cash flow?\",\n",
    "    ],\n",
    "    title=\"Nvidia 10-K Q&A\",\n",
    "    description=\"Use AI21 Conversational RAG to retrieval insights from SEC filings\",\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "\n",
    "demo.launch(server_name=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf3879-1cde-4bdc-9892-5e7c69d48da8",
   "metadata": {},
   "source": [
    "## RAG with AI21 Jamba model in Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3136b5f-4cf8-4a42-9acd-858ff34d5915",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "from langchain_ai21 import ChatAI21\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58b7d2c5-681c-49db-a697-8bd186855455",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "llm = ChatAI21(model=\"jamba-1.5-large\",\n",
    "               max_tokens = 4096,\n",
    "               temperature = 0.4,\n",
    "               top_p = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0786ad5-f719-4d6c-ad93-022994d8b6ef",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./Nvidia_10K_20240128.txt\")\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "900d79a7-171b-4b96-adc5-6723f1da1f9c",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=400)\n",
    "documents = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dda248e-94fb-4c8c-a26b-59afbd9fa1a0",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533410302e9847edb8e6287686a4712a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6b5746e2fd47fa957a8ed9ce1c6e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9b741b48034decab3f975820fab0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9df87c852e942fdb10de76a5117fb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172f63ba03b443819698a2a2e8dc6cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71cece0483e4f3c9fa97b13182e4ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b012882bb894e5f980ca5286101dcd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b710b120c7744238fa77e6bea1eede4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75494637ee82492b9b905fa0b70af027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0dba62be857458fa6dfc5acc03b7c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2034847f67124f3bb3d66ca27c3ba39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "vectorstore = Chroma.from_documents(documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd682da4-1661-46c6-a619-232f0fdcd8a4",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e677c26b-36ef-42e7-bc97-b4bec692d597",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an expert in answering questions based on provided context.\n",
    "    Answer the question based on the provided context below to the best of your ability.\n",
    "    The response must be complete, coherent and concise.\n",
    "    If the answer is not contained in the context, please respond with \"answer not in the document\"\\n\n",
    "    Here is the context you should use to answer the question: \\n\n",
    "    <context>\n",
    "    {context}\n",
    "    </context> \\n\n",
    "    Based on the provided context, answer the following question: {question} \\n\n",
    "    Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f80b4925-74f9-402a-9d4a-d242a681e4ae",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "052e524f-afba-4dd1-9f6d-f7cef551db7a",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2a3976-ecc5-44e5-92bb-dbcd1df324e7",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa70fb23-a348-4b93-aa99-fcae2e9b4ae9",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The company's revenue has increased by 126% from the previous year. This growth was primarily driven by higher demand in the U.S. for the Compute & Networking segment. The company's net income also saw a significant rise, increasing by 581% from the previous year.\n"
     ]
    }
   ],
   "source": [
    "q = \"How has the company revenue and profit changed from last year?\"\n",
    "\n",
    "response = rag_chain.invoke(q)\n",
    "print(f\"Answer: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9657427-71d6-4a34-9397-c8bc543470a9",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './Nvidia_10K_20240128.txt'}, page_content='Income tax expense (benefit) 6.6  (0.7) Net income 48.9  % 16.2  % Reportable Segments Revenue by Reportable Segments Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute & Networking $ 47,405  $ 15,068  $ 32,337  215  % Graphics 13,517  11,906  1,611  14  % Total $ 60,922  $ 26,974  $ 33,948  126  % Operating Income by Reportable Segments Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute & Networking $ 32,016  $ 5,083  $ 26,933  530  % Graphics 5,846  4,552  1,294  28  % All Other (4,890) (5,411) 521  (10) % Total $ 32,972  $ 4,224  $ 28,748  681  % Compute & Networking revenue  ‚Äì The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue  ‚Äì The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income  ‚Äì The year-on-year increase in Compute & Networking and Graphics operating income was driven by higher revenue. 39 Table of Contents All Other operating loss  - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. Concentration of Revenue Revenue by geographic region is designated based on the billing location even if the revenue may be attributable to end customers, such as enterprises and gamers in a different location. Revenue from sales to customers outside of the United States accounted for 56% and 69% of total revenue for fiscal years 2024 and 2023, respectively. Our direct and indirect customers include public cloud, consumer internet companies, enterprises,'),\n",
       " Document(metadata={'source': './Nvidia_10K_20240128.txt'}, page_content='108   Taxes payable 296   467   Operating leases 228   176   Unsettled share repurchases 187   117   Licenses and royalties 182   149   Other 199   69   Total accrued and other current liabilities $ 6,682   $ 4,120   (1) In fiscal years 2024 and 2023, we recorded an expense of approximately $ 1.4  billion and $ 1.1  billion, respectively, in cost of revenue for inventory purchase obligations in excess of our current demand projections, supplier charges and for penalties related to cancellations and underutilization. (2) Deferred revenue primarily includes customer advances and deferrals related to support for hardware and software, license and development arrangements, and cloud services. $ 233  million and $ 35  million of the balance in fiscal 2024 and 2023 respectively, related to customer advances.   Jan 28, 2024 Jan 29, 2023 (In millions) Other Long-Term Liabilities: Income tax payable (1) $ 1,361   $ 1,204   Deferred income tax 462   247   Deferred revenue (2) 573   218   Licenses payable 80   181   Other 65   63   Total other long-term liabilities $ 2,541   $ 1,913   (1) Income tax payable is comprised of the long-term portion of the one-time transition tax payable, unrecognized tax benefits, and related interest and penalties. (2) Deferred revenue primarily includes deferrals related to support for hardware and software. Deferred Revenue The following table shows the changes in deferred revenue during fiscal years 2024 and 2023.   Jan 28, 2024 Jan 29, 2023 (In millions) Balance at beginning of period $ 572   $ 502   Deferred revenue additions during the period 2,038   830   Revenue recognized during the period ( 1,273 ) ( 760 ) Balance at end of period $ 1,337   $ 572   Revenue recognized during fiscal year 2024 that was included in deferred revenue as of January 29, 2023 was $ 338  million. Revenue recognized during fiscal year 2023 that was included in deferred revenue as of January 30, 2022 was $ 282  million. Revenue related to remaining performance'),\n",
       " Document(metadata={'source': './Nvidia_10K_20240128.txt'}, page_content='of this change for the fiscal year ended January 28, 2024 was a benefit of $ 33  million and $ 102  million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $ 135  million and net income of $ 114  million after tax, or $ 0.05  per both basic and diluted share. Revenue Recognition We derive our revenue from product sales, including hardware and systems, license and development arrangements, software licensing, and cloud services. We determine revenue recognition through the following steps: (1) identification of the contract with a customer; (2) identification of the performance obligations in the contract; (3) determination of the transaction price; (4) allocation of the transaction price to the performance obligations in the contract (where revenue is allocated on a relative standalone selling price basis by maximizing the use of observable inputs to determine the standalone selling price for each performance obligation); and (5) recognition of revenue when, or as, we satisfy a performance obligation. Product Sales Revenue Revenue from product sales is recognized upon transfer of control of products to customers in an amount that reflects the consideration we expect to receive in exchange for those products. Certain products are sold with support or an extended warranty for the incorporated system, hardware, and/or software. Support and extended warranty revenue are recognized ratably over the service period, or as services are performed. Revenue is recognized net of allowances for returns, customer programs and any taxes collected from customers. For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales'),\n",
       " Document(metadata={'source': './Nvidia_10K_20240128.txt'}, page_content='$ 5,846   $ ( 4,890 ) $ 32,972   Year Ended Jan 29, 2023:       Revenue $ 15,068   $ 11,906   $ ‚Äî   $ 26,974   Operating income (loss) $ 5,083   $ 4,552   $ ( 5,411 ) $ 4,224   Year Ended Jan 30, 2022:       Revenue $ 11,046   $ 15,868   $ ‚Äî   $ 26,914   Operating income (loss) $ 4,598   $ 8,492   $ ( 3,049 ) $ 10,041   78 Table of Contents NVIDIA Corporation and Subsidiaries Notes to the Consolidated Financial Statements (Continued) Year Ended Jan 28, 2024 Jan 29, 2023 Jan 30, 2022 (In millions) Reconciling items included in \"All Other\" category: Stock-based compensation expense $ ( 3,549 ) $ ( 2,710 ) $ ( 2,004 ) Unallocated cost of revenue and operating expenses ( 728 ) ( 595 ) ( 399 ) Acquisition-related and other costs ( 583 ) ( 674 ) ( 636 ) IP-related and legal settlement costs ( 40 ) ( 23 ) ( 10 ) Restructuring costs and other ‚Äî   ( 54 ) ‚Äî   Acquisition termination cost ‚Äî   ( 1,353 ) ‚Äî   Other 10   ( 2 ) ‚Äî   Total $ ( 4,890 ) $ ( 5,411 ) $ ( 3,049 ) Revenue by geographic areas is designated based upon the billing location of the customer. End customer location may be different than our customer‚Äôs billing location. Revenue by geographic areas was as follows :    Year Ended   Jan 28, 2024 Jan 29, 2023 Jan 30, 2022 Revenue: (In millions) United States $ 26,966   $ 8,292   $ 4,349   Taiwan 13,405   6,986   8,544   China (including Hong Kong) 10,306   5,785   7,111   Other countries 10,245   5,911   6,910   Total revenue $ 60,922   $ 26,974   $ 26,914   Revenue from sales to customers outside of the United States accounted for  56 %,  69 %, and  84 % of total revenue for fiscal years 2024, 2023, and 2022, respectively. The increase in revenue to the United States for fiscal year 2024 was primarily due to higher U.S.-based Compute & Networking segment demand. Sales to one customer represented  13 % of total revenue for fiscal year 2024, which was attributable to the Compute & Networking segment. No customer represented 10% or more of total revenue for fiscal'),\n",
       " Document(metadata={'source': './Nvidia_10K_20240128.txt'}, page_content='ending on the last Sunday in January. Fiscal years 2024, 2023 and 2022 were all 52-week years. Principles of Consolidation Our consolidated financial statements include the accounts of NVIDIA Corporation and our wholly-owned subsidiaries. All intercompany balances and transactions have been eliminated in consolidation. Use of Estimates The preparation of financial statements in conformity with U.S. GAAP requires management to make estimates and assumptions that affect the reported amounts of assets and liabilities and disclosures of contingent assets and liabilities at the date of the financial statements and the reported amounts of revenue and expenses during the reporting period. Actual results could differ materially from our estimates. On an on-going basis, we evaluate our estimates, including those related to revenue recognition, cash equivalents and marketable securities, accounts receivable, inventories and product purchase commitments, income taxes, goodwill, stock-based compensation, litigation, investigation and settlement costs, restructuring and other charges, property, plant, and equipment, and other contingencies. These estimates are based on historical facts and various other assumptions that we believe are reasonable. In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of most of our server, storage, and network equipment from  three  to  four  or  five years , and our assembly and test equipment from  five  to  seven years . The effect of this change for the fiscal year ended January 28, 2024 was a benefit of $ 33  million and $ 102  million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $ 135  million and net income of $ 114  million after tax, or $ 0.05  per both basic and diluted share. Revenue Recognition We derive our revenue from product sales, including'),\n",
       " Document(metadata={'source': './Nvidia_10K_20240128.txt'}, page_content='( 985 ) ( 77 ) ( 24 ) Net cash provided by (used in) investing activities ( 10,566 ) 7,375   ( 9,830 ) Cash flows from financing activities:     Proceeds related to employee stock plans 403   355   281   Payments related to repurchases of common stock ( 9,533 ) ( 10,039 ) ‚Äî   Payments related to tax on restricted stock units ( 2,783 ) ( 1,475 ) ( 1,904 ) Repayment of debt ( 1,250 ) ‚Äî   ( 1,000 ) Dividends paid ( 395 ) ( 398 ) ( 399 ) Principal payments on property and equipment and intangible assets ( 74 ) ( 58 ) ( 83 ) Issuance of debt, net of issuance costs ‚Äî   ‚Äî   4,977   Other ( 1 ) ( 2 ) ( 7 ) Net cash provided by (used in) financing activities ( 13,633 ) ( 11,617 ) 1,865   Change in cash and cash equivalents 3,891   1,399   1,143   Cash and cash equivalents at beginning of period 3,389   1,990   847   Cash and cash equivalents at end of period $ 7,280   $ 3,389   $ 1,990   Supplemental disclosures of cash flow information: Cash paid for income taxes, net $ 6,549   $ 1,404   $ 396   Cash paid for interest $ 252   $ 254   $ 246   See accompanying notes to the consolidated financial statements. 54 Table of Contents NVIDIA Corporation and Subsidiaries Notes to the Consolidated Financial Statements Note 1 -  Organization and Summary of Significant Accounting Policies Our Company Headquartered in Santa Clara, California, NVIDIA was incorporated in California in April 1993 and reincorporated in Delaware in April 1998.  All references to ‚ÄúNVIDIA,‚Äù ‚Äúwe,‚Äù ‚Äúus,‚Äù ‚Äúour‚Äù or the ‚ÄúCompany‚Äù mean NVIDIA Corporation and its subsidiaries. Fiscal Year We operate on a 52- or 53-week year, ending on the last Sunday in January. Fiscal years 2024, 2023 and 2022 were all 52-week years. Principles of Consolidation Our consolidated financial statements include the accounts of NVIDIA Corporation and our wholly-owned subsidiaries. All intercompany balances and transactions have been eliminated in consolidation. Use of Estimates The preparation of financial statements in conformity with'),\n",
       " Document(metadata={'source': './Nvidia_10K_20240128.txt'}, page_content='and legislation on Pillar Two and we continue to evaluate the impact on our financial position of the global implementation of these rules. Based on enacted laws, Pillar Two is not expected to materially impact our effective tax rate or cash flows in the next fiscal year. New legislation or guidance could change our current assessment. Refer to Note 14 of the Notes to the Consolidated Financial Statements in Part IV, Item 15 of this Annual Report on Form 10-K for additional information. 41 Table of Contents Liquidity and Capital Resources   Jan 28, 2024 Jan 29, 2023   (In millions) Cash and cash equivalents $ 7,280  $ 3,389  Marketable securities 18,704  9,907  Cash, cash equivalents, and marketable securities $ 25,984  $ 13,296    Year Ended Jan 28, 2024 Jan 29, 2023   (In millions) Net cash provided by operating activities $ 28,090  $ 5,641  Net cash provided by (used in) investing activities $ (10,566) $ 7,375  Net cash used in financing activities $ (13,633) $ (11,617) Our investment policy requires the purchase of highly rated fixed income securities, the diversification of investment types and credit exposures, and certain maturity limits on our portfolio. Cash provided by operating activities increased in fiscal year 2024 compared to fiscal year 2023, due to growth in revenue. Accounts receivable balance in fiscal year 2024 reflected $557 million from customer payments received ahead of the invoice due date. Cash provided by investing activities decreased in fiscal year 2024 compared to fiscal year 2023, primarily driven by lower marketable securities maturities and higher purchases of marketable securities. Cash used in financing activities increased in fiscal year 2024 compared to fiscal year 2023, due to a debt repayment and higher tax payments related to RSUs, partially offset by lower share repurchases. Liquidity Our primary sources of liquidity are our cash, cash equivalents, and marketable securities, and the cash generated by our operations. At the'),\n",
       " Document(metadata={'source': './Nvidia_10K_20240128.txt'}, page_content=\"the future fluctuate, and if our operating results are below the expectations of securities analysts or investors, our stock price could decline. Our operating results have in the past fluctuated and may continue to fluctuate due to numerous of these risk factors. Therefore, investors should not rely on our past results of operations as an indication of our future performance. Additional factors that could affect our results of operations include, but are not limited to: ‚Ä¢ our ability to adjust spending due to the multi-year development cycle for some of our products and services; ‚Ä¢ our ability to comply with our contractual obligations to customers; ‚Ä¢ our extended payment term arrangements with certain customers, the inability of some customers to make required payments, our ability to obtain credit insurance for customers with extended payment terms, and customer bad debt write-offs; ‚Ä¢ our vendors' payment requirements; ‚Ä¢ unanticipated costs associated with environmental liabilities; and ‚Ä¢ changes in financial accounting standards or interpretations of existing standards. Any of the factors discussed above could prevent us from achieving our anticipated financial results. For example, we have granted and may continue to grant extended payment terms to some customers, particularly during macroeconomic downturns, which could impact our ability to collect payment. Our vendors have requested and may continue to ask for shorter payment terms, which may impact our cash flow generation. These arrangements reduce the cash we have available for general business operations. In addition, the pace of growth in our operating expenses and investments may lag our revenue growth, creating volatility or periods where profitability levels may not be sustainable. Failure to meet our expectations or the expectations of our investors or security analysts is likely to cause our stock price to decline, as it has in the past, or experience substantial price volatility. 24 Table of\"),\n",
       " Document(metadata={'source': './Nvidia_10K_20240128.txt'}, page_content='to isolate and quantify, these macroeconomic factors can also impact our supply chain and manufacturing costs, employee wages, costs for capital equipment and value of our investments. Our product and solution pricing generally does not fluctuate with short-term changes in our costs. Within our supply chain, we continuously manage product availability and costs with our vendors.  Israel and Hamas Conflict We are monitoring the impact of the geopolitical conflict in and around Israel on our operations, including the health and safety of our approximately 3,700 employees in the region who primarily support the research and development, operations, and sales and marketing of our networking products. Our operating expenses in fiscal year 2024 include expenses for financial support to impacted employees and charitable activity. We believe our global supply chain for our networking products has not experienced any significant impact. Further, in connection with the conflict, a substantial number of our employees in the region have been called-up for active military duty in Israel. Accordingly, some of our employees in Israel have been absent for an extended period and they or others may continue to be absent, which may cause disruption to our product development or operations. We did not experience any significant impact or expense to our business; however, if the conflict is further extended, it could impact future product development, operations, and revenue or create other uncertainty for our business. 35 Table of Contents Fiscal Year 2024 Summary   Year Ended   Jan 28, 2024 Jan 29, 2023 Change ($ in millions, except per share data) Revenue $ 60,922  $ 26,974  Up 126% Gross margin 72.7  % 56.9  % Up 15.8 pts Operating expenses $ 11,329  $ 11,132  Up 2% Operating income $ 32,972  $ 4,224  Up 681% Net income $ 29,760  $ 4,368  Up 581% Net income per diluted share $ 11.93  $ 1.74  Up 586% We specialize in markets where our computing platforms can provide tremendous'),\n",
       " Document(metadata={'source': './Nvidia_10K_20240128.txt'}, page_content='increases. Acquisition Termination Cost We recorded an acquisition termination cost related to the Arm transaction of $1.4 billion in fiscal year 2023 reflecting the write-off of the prepayment provided at signing. 40 Table of Contents Other Income (Expense), Net   Year Ended   Jan 28, 2024 Jan 29, 2023 $ Change   ($ in millions) Interest income $ 866  $ 267  $ 599  Interest expense (257) (262) 5  Other, net 237  (48) 285  Other income (expense), net $ 846  $ (43) $ 889  Interest income consists of interest earned on cash, cash equivalents and marketable securities. The increase in interest income was due to higher yields on higher cash balances. Interest expense is comprised of coupon interest and debt discount amortization related to our notes. Other, net, consists of realized or unrealized gains and losses from investments in non-affiliated entities and the impact of changes in foreign currency rates. Change in Other, net, compared to fiscal year 2023 was driven by changes in value from our non-affiliated investments. Refer to Note 9 of the Notes to the Consolidated Financial Statements in Part IV, Item 15 of this Annual Report on Form 10-K for additional information regarding our investments in non-affiliated entities. Income Taxes We recognized income tax expense of $4.1 billion for fiscal year 2024 and income tax benefit of $187 million for fiscal year 2023. Income tax as a percentage of income before income tax was an expense of 12.0% for fiscal year 2024 and a benefit of 4.5% for fiscal year 2023. During the third quarter of fiscal year 2024, the Internal Revenue Service, or IRS, audit of our federal income tax returns for fiscal years 2018 and 2019 was resolved. We recognized a non-cash net benefit of $145 million, related to this IRS audit resolution, for effectively settled positions. This benefit consists of a reduction in unrecognized tax benefits of $236 million and related accrued interest of $17 million, net of federal benefit, partially offset by')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.invoke(q)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "965c3a72-0e59-4161-b875-b5db07192b84",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Question: What are the main business risks for the company?\n",
      "Answer: The company faces several business risks, including failure to meet industry needs, competition, inaccuracies in customer demand estimation, dependency on third-party suppliers, product defects, adverse economic conditions, security breaches, business disruptions, climate change, challenges in realizing business investments or acquisitions, reliance on a limited number of partners and distributors, difficulties in attracting and retaining key employees, and potential disruptions to business processes and information systems.\n",
      "================================================================================\n",
      "Question: What are the key financial metrics of the company?\n",
      "Answer: The key financial metrics of the company include:\n",
      "\n",
      "1. Gross deferred tax assets of $8,000 million in 2024 and $5,154 million in 2023.\n",
      "2. Total deferred tax assets of $6,448 million in 2024 and $3,670 million in 2023.\n",
      "3. Deferred tax liabilities of $831 million in 2024 and $522 million in 2023.\n",
      "4. Net deferred tax asset of $5,617 million in 2024 and $3,148 million in 2023.\n",
      "5. Gross unrealized gains of $270 million and cumulative gross unrealized losses and impairments of $45 million as of January 28, 2024.\n",
      "6. Accounts receivable balance with two customers accounting for 24% and 11% as of January 28, 2024.\n",
      "7. Inventories totaling $5,282 million as of January 28, 2024.\n",
      "8. Property and equipment, net of $3,914 million as of January 28, 2024.\n",
      "9. Cash and cash equivalents of $7,280 million as of January 28, 2024.\n",
      "10. Marketable securities of $18,704 million as of January 28, 2024.\n",
      "11. Total inventories of $5,282 million as of January 28, 2024.\n",
      "12. Research and development expenses of $8,675 million in 2024.\n",
      "13. Sales, general and administrative expenses of $2,654 million in 2024.\n",
      "14. Acquisition termination cost of $1.4 billion in 2023.\n",
      "15. Interest income of $866 million in 2024.\n",
      "16. Interest expense of $257 million in 2024.\n",
      "================================================================================\n",
      "Question: What is the profit growth of the company in the reporting period?\n",
      "Answer: The company's profit growth in the reporting period was 681%.\n",
      "================================================================================\n",
      "Question: Did the company have a cybersecurity incident based on the following SEC filing document?\n",
      "Answer: Answer not in the document.\n"
     ]
    }
   ],
   "source": [
    "questions = [\"What are the main business risks for the company?\",\n",
    "             \"What are the key financial metrics of the company?\",\n",
    "             \"What is the profit growth of the company in the reporting period?\",\n",
    "             \"Did the company have a cybersecurity incident based on the following SEC filing document?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    response = rag_chain.invoke(q)\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Question: {q}\")\n",
    "    print(f\"Answer: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bd7006f-b0d7-40a0-bff0-b22435db2bd7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "vectorstore.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b73e4d-555c-47a6-a10f-76fcd73dadb7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f7257-4478-477e-9cd0-7373ccb6be04",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a0d69b-f852-44e0-9201-48463a0814b0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76821a5-0fde-4d66-bded-98f0b9e05527",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac6f265-f706-4c4f-ac9b-c976dcd292b3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e6c853-551a-4aa1-91ed-f2faf4953a47",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
