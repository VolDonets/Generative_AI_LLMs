{
  "2010.00488v1": {
    "title": "Developing Effective Community Network Analysis Tools According to Visualization Psychology",
    "authors": [
      "Darren J. Edwards",
      "Min Chen"
    ],
    "summary": "Visualization is a useful technology in health science, and especially for\ncommunity network analysis. Because visualization applications in healthcare\nare typically risk-averse, health psychologists can play a significant role in\nensuring appropriate and effective uses of visualization techniques in\nhealthcare. In this paper, we examine the role of health psychologists in the\ntriangle of \"health science\", \"visualization technology\", and \"visualization\npsychology\". We conclude that health psychologists can use visualization to aid\ndata intelligence workflows in healthcare and health psychology, while\nresearching into visualization psychology to aid the improvement and\noptimization of data visualization processes.",
    "pdf_url": "http://arxiv.org/pdf/2010.00488v1",
    "published": "2020-10-01"
  },
  "1903.05434v1": {
    "title": "Visual Semantic Information Pursuit: A Survey",
    "authors": [
      "Daqi Liu",
      "Miroslaw Bober",
      "Josef Kittler"
    ],
    "summary": "Visual semantic information comprises two important parts: the meaning of\neach visual semantic unit and the coherent visual semantic relation conveyed by\nthese visual semantic units. Essentially, the former one is a visual perception\ntask while the latter one corresponds to visual context reasoning. Remarkable\nadvances in visual perception have been achieved due to the success of deep\nlearning. In contrast, visual semantic information pursuit, a visual scene\nsemantic interpretation task combining visual perception and visual context\nreasoning, is still in its early stage. It is the core task of many different\ncomputer vision applications, such as object detection, visual semantic\nsegmentation, visual relationship detection or scene graph generation. Since it\nhelps to enhance the accuracy and the consistency of the resulting\ninterpretation, visual context reasoning is often incorporated with visual\nperception in current deep end-to-end visual semantic information pursuit\nmethods. However, a comprehensive review for this exciting area is still\nlacking. In this survey, we present a unified theoretical paradigm for all\nthese methods, followed by an overview of the major developments and the future\ntrends in each potential direction. The common benchmark datasets, the\nevaluation metrics and the comparisons of the corresponding methods are also\nintroduced.",
    "pdf_url": "http://arxiv.org/pdf/1903.05434v1",
    "published": "2019-03-13"
  },
  "2102.06343v1": {
    "title": "Personalized Visualization Recommendation",
    "authors": [
      "Xin Qian",
      "Ryan A. Rossi",
      "Fan Du",
      "Sungchul Kim",
      "Eunyee Koh",
      "Sana Malik",
      "Tak Yeon Lee",
      "Nesreen K. Ahmed"
    ],
    "summary": "Visualization recommendation work has focused solely on scoring\nvisualizations based on the underlying dataset and not the actual user and\ntheir past visualization feedback. These systems recommend the same\nvisualizations for every user, despite that the underlying user interests,\nintent, and visualization preferences are likely to be fundamentally different,\nyet vitally important. In this work, we formally introduce the problem of\npersonalized visualization recommendation and present a generic learning\nframework for solving it. In particular, we focus on recommending\nvisualizations personalized for each individual user based on their past\nvisualization interactions (e.g., viewed, clicked, manually created) along with\nthe data from those visualizations. More importantly, the framework can learn\nfrom visualizations relevant to other users, even if the visualizations are\ngenerated from completely different datasets. Experiments demonstrate the\neffectiveness of the approach as it leads to higher quality visualization\nrecommendations tailored to the specific user intent and preferences. To\nsupport research on this new problem, we release our user-centric visualization\ncorpus consisting of 17.4k users exploring 94k datasets with 2.3 million\nattributes and 32k user-generated visualizations.",
    "pdf_url": "http://arxiv.org/pdf/2102.06343v1",
    "published": "2021-02-12"
  },
  "1907.05454v1": {
    "title": "Data by Proxy -- Material Traces as Autographic Visualizations",
    "authors": [
      "Dietmar Offenhuber"
    ],
    "summary": "Information visualization limits itself, per definition, to the domain of\nsymbolic information. This paper discusses arguments why the field should also\nconsider forms of data that are not symbolically encoded, including physical\ntraces and material indicators. Continuing a provocation presented by Pat\nHanrahan in his 2004 IEEE Vis capstone address, this paper compares physical\ntraces to visualizations and describes the techniques and visual practices for\nproducing, revealing, and interpreting them. By contrasting information\nvisualization with a speculative counter model of autographic visualization,\nthis paper examines the design principles for material data. Autographic\nvisualization addresses limitations of information visualization, such as the\ninability to directly reflect the material circumstances of data generation.\nThe comparison between the two models allows probing the epistemic assumptions\nbehind information visualization and uncovers linkages with the rich history of\nscientific visualization and trace reading.",
    "pdf_url": "http://arxiv.org/pdf/1907.05454v1",
    "published": "2019-07-11"
  },
  "2408.01272v1": {
    "title": "Does This Have a Particular Meaning? Interactive Pattern Explanation for Network Visualizations",
    "authors": [
      "Xinhuan Shu",
      "Alexis Pister",
      "Junxiu Tang",
      "Fanny Chevalier",
      "Benjamin Bach"
    ],
    "summary": "This paper presents an interactive technique to explain visual patterns in\nnetwork visualizations to analysts who do not understand these visualizations\nand who are learning to read them. Learning a visualization requires mastering\nits visual grammar and decoding information presented through visual marks,\ngraphical encodings, and spatial configurations. To help people learn network\nvisualization designs and extract meaningful information, we introduce the\nconcept of interactive pattern explanation that allows viewers to select an\narbitrary area in a visualization, then automatically mines the underlying data\npatterns, and explains both visual and data patterns present in the viewer's\nselection. In a qualitative and a quantitative user study with a total of 32\nparticipants, we compare interactive pattern explanations to textual-only and\nvisual-only (cheatsheets) explanations. Our results show that interactive\nexplanations increase learning of i) unfamiliar visualizations, ii) patterns in\nnetwork science, and iii) the respective network terminology.",
    "pdf_url": "http://arxiv.org/pdf/2408.01272v1",
    "published": "2024-08-02"
  }
}